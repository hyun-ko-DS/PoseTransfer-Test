"""
extracted_keypointsì˜ originalê³¼ ìƒì„± ëª¨ë¸ ê°„ PCK/PCKh í‰ê°€ ìŠ¤í¬ë¦½íŠ¸

extracted_keypoints/original/{image_type}/ì˜ JSON íŒŒì¼ê³¼
extracted_keypoints/{model_name}/{prompt_version}/{image_type}/ì˜ JSON íŒŒì¼ì„ ë¹„êµí•˜ì—¬
PCK/PCKh ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

íŒŒì¼ëª… ë§¤ì¹­ ê·œì¹™:
- original/full/kp_full_1_origin_keypoints.json â†” nano_banana/short/full/full_bg_1_kp_1_keypoints.json
- kp_ ë’¤ì˜ ìˆ«ìë¡œ ë§¤ì¹­ (bg, no_bgëŠ” ë¬´ì‹œ)
"""

import argparse
import json
import re
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from PIL import Image

# OpenPose BODY_25 í‚¤í¬ì¸íŠ¸ ì´ë¦„ (25ê°œ)
KEYPOINT_NAMES = [
    "nose", "neck", "right_shoulder", "right_elbow", "right_wrist",
    "left_shoulder", "left_elbow", "left_wrist", "mid_hip",
    "right_hip", "right_knee", "right_ankle",
    "left_hip", "left_knee", "left_ankle",
    "right_eye", "left_eye", "right_ear", "left_ear",
    "left_big_toe", "left_small_toe", "left_heel",
    "right_big_toe", "right_small_toe", "right_heel"
]


def load_keypoints_from_json(json_path: Path) -> Optional[Dict[str, Tuple[float, float, float]]]:
    """
    OpenPose JSON íŒŒì¼ì—ì„œ í‚¤í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        json_path: OpenPose JSON íŒŒì¼ ê²½ë¡œ
    
    Returns:
        í‚¤í¬ì¸íŠ¸ ë”•ì…”ë„ˆë¦¬: {í‚¤í¬ì¸íŠ¸ëª…: (x, y, confidence), ...} ë˜ëŠ” None
    """
    if not json_path.exists():
        return None
    
    try:
        with open(json_path, 'r') as f:
            data = json.load(f)
        
        if 'people' not in data or len(data['people']) == 0:
            return None
        
        # ì²« ë²ˆì§¸ ì‚¬ëŒì˜ í‚¤í¬ì¸íŠ¸ë§Œ ì‚¬ìš©
        person = data['people'][0]
        
        # BODY_25 í‚¤í¬ì¸íŠ¸ (25ê°œ, ê°ê° [x, y, confidence])
        pose_keypoints = np.array(person.get('pose_keypoints_2d', [])).reshape(-1, 3)
        
        if len(pose_keypoints) == 0:
            return None
        
        # í‚¤í¬ì¸íŠ¸ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        keypoints = {}
        
        for idx, name in enumerate(KEYPOINT_NAMES):
            if idx < len(pose_keypoints):
                x, y, confidence = pose_keypoints[idx]
                if confidence > 0:
                    keypoints[name] = (float(x), float(y), float(confidence))
        
        return keypoints if keypoints else None
    except Exception as e:
        print(f"âš ï¸  JSON ë¡œë“œ ì‹¤íŒ¨ ({json_path}): {e}")
        return None


def extract_kp_num_from_original_json(filename: str) -> Optional[str]:
    """
    original í´ë”ì˜ JSON íŒŒì¼ëª…ì—ì„œ í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    ì˜ˆ: "kp_full_1_origin_keypoints.json" -> "1"
        "kp_half_3_origin_keypoints.json" -> "3"
    
    Args:
        filename: íŒŒì¼ëª…
    
    Returns:
        í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ (ë¬¸ìì—´) ë˜ëŠ” None
    """
    # íŒ¨í„´: kp_{image_type}_{num}_origin_keypoints.json
    match = re.search(r'kp_(?:full|half)_(\d+)_origin', filename)
    if match:
        return match.group(1)
    return None


def extract_kp_num_from_generated_json(filename: str) -> Optional[str]:
    """
    ìƒì„±ëœ ëª¨ë¸ì˜ JSON íŒŒì¼ëª…ì—ì„œ í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    ì˜ˆ: "full_bg_1_kp_1_keypoints.json" -> "1"
        "half_nobg_2_kp_3_keypoints.json" -> "3"
        "selfie_1_kp_2_keypoints.json" -> "2"
    
    Args:
        filename: íŒŒì¼ëª…
    
    Returns:
        í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ (ë¬¸ìì—´) ë˜ëŠ” None
    """
    # íŒ¨í„´: ..._kp_{num}_keypoints.json
    match = re.search(r'_kp_(\d+)_keypoints', filename)
    if match:
        return match.group(1)
    return None


def find_original_json(
    extracted_keypoints_base: Path,
    image_type: str,
    kp_num: str
) -> Optional[Path]:
    """
    original í´ë”ì—ì„œ í•´ë‹¹ í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ì˜ JSON íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    
    Args:
        extracted_keypoints_base: extracted_keypoints ê¸°ë³¸ ë””ë ‰í† ë¦¬
        image_type: ì´ë¯¸ì§€ íƒ€ì… ('full' ë˜ëŠ” 'half')
        kp_num: í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ (ë¬¸ìì—´)
    
    Returns:
        JSON íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    original_dir = extracted_keypoints_base / "original" / image_type
    
    if not original_dir.exists():
        return None
    
    # íŒ¨í„´: kp_{image_type}_{kp_num}_origin_keypoints.json
    pattern = f"kp_{image_type}_{kp_num}_origin_keypoints.json"
    json_path = original_dir / pattern
    
    if json_path.exists():
        return json_path
    
    # ëŒ€ì²´ íŒ¨í„´ ì‹œë„ (í˜¹ì‹œ ë‹¤ë¥¸ í˜•ì‹ì¼ ê²½ìš°)
    for json_file in original_dir.glob(f"*kp*{kp_num}*.json"):
        return json_file
    
    return None


def calculate_pck(
    predicted_keypoints: Dict[str, Tuple[float, float, float]],
    ground_truth_keypoints: Dict[str, Tuple[float, float, float]],
    image_width: int,
    image_height: int,
    alpha: float = 0.2
) -> float:
    """
    PCK (Percentage of Correct Keypoints)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        predicted_keypoints: ì˜ˆì¸¡ëœ í‚¤í¬ì¸íŠ¸ ë”•ì…”ë„ˆë¦¬
        ground_truth_keypoints: ì •ë‹µ í‚¤í¬ì¸íŠ¸ ë”•ì…”ë„ˆë¦¬
        image_width: ì´ë¯¸ì§€ ë„ˆë¹„
        image_height: ì´ë¯¸ì§€ ë†’ì´
        alpha: ì„ê³„ê°’ (ì´ë¯¸ì§€ ëŒ€ê°ì„  ê¸¸ì´ì˜ ë¹„ìœ¨, ê¸°ë³¸ê°’: 0.2)
    
    Returns:
        PCK ì ìˆ˜ (0.0 ~ 1.0)
    """
    image_diagonal = np.sqrt(image_width**2 + image_height**2)
    threshold = alpha * image_diagonal
    
    correct_count = 0
    total_count = 0
    
    # ê³µí†µ í‚¤í¬ì¸íŠ¸ë§Œ ë¹„êµ
    common_keys = set(predicted_keypoints.keys()) & set(ground_truth_keypoints.keys())
    
    for key in common_keys:
        pred_x, pred_y, pred_conf = predicted_keypoints[key]
        gt_x, gt_y, gt_conf = ground_truth_keypoints[key]
        
        # confidenceê°€ 0.3 ì´ìƒì¸ í‚¤í¬ì¸íŠ¸ë§Œ í‰ê°€
        if pred_conf >= 0.3 and gt_conf >= 0.3:
            distance = np.sqrt((pred_x - gt_x)**2 + (pred_y - gt_y)**2)
            if distance <= threshold:
                correct_count += 1
            total_count += 1
    
    return correct_count / total_count if total_count > 0 else 0.0


def calculate_pckh(
    predicted_keypoints: Dict[str, Tuple[float, float, float]],
    ground_truth_keypoints: Dict[str, Tuple[float, float, float]],
    image_width: int,
    image_height: int,
    alpha: float = 0.5
) -> float:
    """
    PCKh (PCK with head size normalization)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        predicted_keypoints: ì˜ˆì¸¡ëœ í‚¤í¬ì¸íŠ¸ ë”•ì…”ë„ˆë¦¬
        ground_truth_keypoints: ì •ë‹µ í‚¤í¬ì¸íŠ¸ ë”•ì…”ë„ˆë¦¬
        image_width: ì´ë¯¸ì§€ ë„ˆë¹„
        image_height: ì´ë¯¸ì§€ ë†’ì´
        alpha: ì„ê³„ê°’ (ë¨¸ë¦¬ í¬ê¸°ì˜ ë¹„ìœ¨, ê¸°ë³¸ê°’: 0.5)
    
    Returns:
        PCKh ì ìˆ˜ (0.0 ~ 1.0)
    """
    # ë¨¸ë¦¬ í¬ê¸° ê³„ì‚° (ê·€ ë˜ëŠ” ëˆˆ ì‚¬ì´ ê±°ë¦¬)
    head_size = 50.0  # ê¸°ë³¸ê°’
    
    if "left_ear" in ground_truth_keypoints and "right_ear" in ground_truth_keypoints:
        left_ear = ground_truth_keypoints["left_ear"]
        right_ear = ground_truth_keypoints["right_ear"]
        if left_ear[2] > 0.3 and right_ear[2] > 0.3:
            head_size = np.sqrt(
                (left_ear[0] - right_ear[0])**2 + 
                (left_ear[1] - right_ear[1])**2
            )
    
    if head_size <= 0 and "left_eye" in ground_truth_keypoints and "right_eye" in ground_truth_keypoints:
        left_eye = ground_truth_keypoints["left_eye"]
        right_eye = ground_truth_keypoints["right_eye"]
        if left_eye[2] > 0.3 and right_eye[2] > 0.3:
            head_size = np.sqrt(
                (left_eye[0] - right_eye[0])**2 + 
                (left_eye[1] - right_eye[1])**2
            )
    
    if head_size <= 0:
        head_size = (image_width + image_height) / 10  # ê¸°ë³¸ê°’
    
    threshold = alpha * head_size
    
    correct_count = 0
    total_count = 0
    
    # ê³µí†µ í‚¤í¬ì¸íŠ¸ë§Œ ë¹„êµ
    common_keys = set(predicted_keypoints.keys()) & set(ground_truth_keypoints.keys())
    
    for key in common_keys:
        pred_x, pred_y, pred_conf = predicted_keypoints[key]
        gt_x, gt_y, gt_conf = ground_truth_keypoints[key]
        
        # confidenceê°€ 0.3 ì´ìƒì¸ í‚¤í¬ì¸íŠ¸ë§Œ í‰ê°€
        if pred_conf >= 0.3 and gt_conf >= 0.3:
            distance = np.sqrt((pred_x - gt_x)**2 + (pred_y - gt_y)**2)
            if distance <= threshold:
                correct_count += 1
            total_count += 1
    
    return correct_count / total_count if total_count > 0 else 0.0


def evaluate_extracted_keypoints(
    model_name: str,
    prompt_version: str,
    extracted_keypoints_base: Path = Path("extracted_keypoints"),
    output_dir: Path = Path("evaluations/pck")
) -> Dict:
    """
    extracted_keypointsì˜ originalê³¼ ìƒì„± ëª¨ë¸ ê°„ PCK/PCKh í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        model_name: ëª¨ë¸ ì´ë¦„ (ì˜ˆ: 'nano_banana')
        prompt_version: í”„ë¡¬í”„íŠ¸ ë²„ì „ (ì˜ˆ: 'short', 'medium', 'long')
        extracted_keypoints_base: extracted_keypoints ê¸°ë³¸ ë””ë ‰í† ë¦¬
        output_dir: ê²°ê³¼ ì¶œë ¥ ë””ë ‰í† ë¦¬
    
    Returns:
        í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print(f"\n{'='*60}")
    print(f"PCK/PCKh í‰ê°€ ì‹œì‘: {model_name}/{prompt_version}")
    print(f"{'='*60}\n")
    
    # original í´ë” í™•ì¸
    original_base = extracted_keypoints_base / "original"
    if not original_base.exists():
        print(f"âš ï¸  original í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {original_base}")
        return {}
    
    # ìƒì„± ëª¨ë¸ í´ë” í™•ì¸
    generated_dir = extracted_keypoints_base / model_name / prompt_version
    if not generated_dir.exists():
        print(f"âš ï¸  ìƒì„± ëª¨ë¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {generated_dir}")
        return {}
    
    # ì´ë¯¸ì§€ íƒ€ì…ë³„ë¡œ ì²˜ë¦¬ (originalì—ëŠ” full, halfë§Œ ìˆìŒ)
    image_types = ["full", "half"]
    results = []
    
    for image_type in image_types:
        original_type_dir = original_base / image_type
        generated_type_dir = generated_dir / image_type
        
        if not original_type_dir.exists():
            print(f"âš ï¸  original/{image_type} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {original_type_dir}")
            continue
        
        if not generated_type_dir.exists():
            print(f"âš ï¸  {model_name}/{prompt_version}/{image_type} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {generated_type_dir}")
            continue
        
        print(f"ğŸ“ ì´ë¯¸ì§€ íƒ€ì…: {image_type}")
        
        # full, halfëŠ” bg, no_bg êµ¬ë¶„ (selfieëŠ” ë³„ë„ ì²˜ë¦¬)
        bg_types = ["bg", "no_bg"]
        
        for bg_type in bg_types:
            bg_dir = generated_type_dir / bg_type
            
            if not bg_dir.exists():
                print(f"  âš ï¸  {bg_type} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {bg_dir}")
                continue
            
            print(f"  ğŸ“‚ ë°°ê²½ íƒ€ì…: {bg_type}")
            
            # JSON íŒŒì¼ ì°¾ê¸°
            json_files = list(bg_dir.glob("*_keypoints.json"))
            
            print(f"    ğŸ“¸ ë°œê²¬ëœ JSON íŒŒì¼: {len(json_files)}ê°œ")
            
            for json_path in json_files:
                try:
                    # ìƒì„±ëœ ëª¨ë¸ì˜ JSONì—ì„œ í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ ì¶”ì¶œ
                    kp_num = extract_kp_num_from_generated_json(json_path.name)
                    
                    if kp_num is None:
                        print(f"    âš ï¸  í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path.name}")
                        continue
                    
                    # original í´ë”ì—ì„œ ëŒ€ì‘í•˜ëŠ” JSON ì°¾ê¸°
                    original_json_path = find_original_json(
                        extracted_keypoints_base, image_type, kp_num
                    )
                    
                    if original_json_path is None:
                        print(f"    âš ï¸  original JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: kp_{image_type}_{kp_num}")
                        continue
                    
                    # í‚¤í¬ì¸íŠ¸ ë¡œë“œ
                    predicted_keypoints = load_keypoints_from_json(json_path)
                    ground_truth_keypoints = load_keypoints_from_json(original_json_path)
                    
                    if predicted_keypoints is None:
                        print(f"    âš ï¸  ìƒì„± ëª¨ë¸ í‚¤í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path.name}")
                        continue
                    
                    if ground_truth_keypoints is None:
                        print(f"    âš ï¸  original í‚¤í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {original_json_path.name}")
                        continue
                    
                    # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸° (ìƒì„±ëœ ëª¨ë¸ì˜ JSONê³¼ ê°™ì€ ì´ë¦„ì˜ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°)
                    # JSON íŒŒì¼ëª…ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„±
                    image_stem = json_path.stem.replace("_keypoints", "")
                    image_path = json_path.parent / f"{image_stem}.png"
                    if not image_path.exists():
                        image_path = json_path.parent / f"{image_stem}.jpg"
                    if not image_path.exists():
                        image_path = json_path.parent / f"{image_stem}.jpeg"
                    
                    if image_path.exists():
                        pred_image = Image.open(image_path)
                        pred_width, pred_height = pred_image.size
                    else:
                        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ original ì´ë¯¸ì§€ í¬ê¸° ì‚¬ìš©
                        original_image_stem = original_json_path.stem.replace("_keypoints", "")
                        original_image_path = original_json_path.parent / f"{original_image_stem}.png"
                        if not original_image_path.exists():
                            original_image_path = original_json_path.parent / f"{original_image_stem}.jpg"
                        if original_image_path.exists():
                            pred_image = Image.open(original_image_path)
                            pred_width, pred_height = pred_image.size
                        else:
                            # ê¸°ë³¸ê°’ ì‚¬ìš©
                            pred_width, pred_height = 1920, 1080
                    
                    # PCK ê³„ì‚° (ì—¬ëŸ¬ alpha ê°’)
                    pck_01 = calculate_pck(
                        predicted_keypoints, ground_truth_keypoints,
                        pred_width, pred_height, alpha=0.1
                    )
                    pck_02 = calculate_pck(
                        predicted_keypoints, ground_truth_keypoints,
                        pred_width, pred_height, alpha=0.2
                    )
                    
                    # PCKh ê³„ì‚°
                    pckh_05 = calculate_pckh(
                        predicted_keypoints, ground_truth_keypoints,
                        pred_width, pred_height, alpha=0.5
                    )
                    
                    result = {
                        "generated_json": str(json_path),
                        "original_json": str(original_json_path),
                        "image_type": image_type,
                        "bg_type": bg_type,
                        "kp_num": kp_num,
                        "pck_0.1": round(pck_01, 4),
                        "pck_0.2": round(pck_02, 4),
                        "pckh_0.5": round(pckh_05, 4),
                    }
                    
                    results.append(result)
                    print(f"    âœ“ {json_path.name} â†” {original_json_path.name}: PCK@0.2={pck_02:.4f}, PCKh@0.5={pckh_05:.4f}")
                    
                except Exception as e:
                    print(f"    âŒ ì˜¤ë¥˜ ë°œìƒ ({json_path.name}): {e}")
                    import traceback
                    traceback.print_exc()
                    continue
        
        # selfie ì²˜ë¦¬ (ë³„ë„)
        if image_type == "half":  # selfieëŠ” halfì™€ í•¨ê»˜ ì²˜ë¦¬
            selfie_dir = generated_dir / "selfie"
            if selfie_dir.exists():
                print(f"\nğŸ“ ì´ë¯¸ì§€ íƒ€ì…: selfie")
                print(f"  ğŸ“‚ ë°°ê²½ íƒ€ì…: ì—†ìŒ (selfie)")
                
                json_files = list(selfie_dir.glob("*_keypoints.json"))
                print(f"    ğŸ“¸ ë°œê²¬ëœ JSON íŒŒì¼: {len(json_files)}ê°œ")
                
                for json_path in json_files:
                    try:
                        kp_num = extract_kp_num_from_generated_json(json_path.name)
                        
                        if kp_num is None:
                            print(f"    âš ï¸  í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_path.name}")
                            continue
                        
                        # selfieëŠ” halfì™€ ë§¤ì¹­
                        original_json_path = find_original_json(
                            extracted_keypoints_base, "half", kp_num
                        )
                        
                        if original_json_path is None:
                            print(f"    âš ï¸  original JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: kp_half_{kp_num}")
                            continue
                        
                        predicted_keypoints = load_keypoints_from_json(json_path)
                        ground_truth_keypoints = load_keypoints_from_json(original_json_path)
                        
                        if predicted_keypoints is None or ground_truth_keypoints is None:
                            continue
                        
                        # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
                        image_stem = json_path.stem.replace("_keypoints", "")
                        image_path = json_path.parent / f"{image_stem}.png"
                        if not image_path.exists():
                            image_path = json_path.parent / f"{image_stem}.jpg"
                        
                        if image_path.exists():
                            pred_image = Image.open(image_path)
                            pred_width, pred_height = pred_image.size
                        else:
                            pred_width, pred_height = 1920, 1080
                        
                        pck_01 = calculate_pck(
                            predicted_keypoints, ground_truth_keypoints,
                            pred_width, pred_height, alpha=0.1
                        )
                        pck_02 = calculate_pck(
                            predicted_keypoints, ground_truth_keypoints,
                            pred_width, pred_height, alpha=0.2
                        )
                        pckh_05 = calculate_pckh(
                            predicted_keypoints, ground_truth_keypoints,
                            pred_width, pred_height, alpha=0.5
                        )
                        
                        result = {
                            "generated_json": str(json_path),
                            "original_json": str(original_json_path),
                            "image_type": "selfie",
                            "bg_type": None,
                            "kp_num": kp_num,
                            "pck_0.1": round(pck_01, 4),
                            "pck_0.2": round(pck_02, 4),
                            "pckh_0.5": round(pckh_05, 4),
                        }
                        
                        results.append(result)
                        print(f"    âœ“ {json_path.name} â†” {original_json_path.name}: PCK@0.2={pck_02:.4f}, PCKh@0.5={pckh_05:.4f}")
                        
                    except Exception as e:
                        print(f"    âŒ ì˜¤ë¥˜ ë°œìƒ ({json_path.name}): {e}")
                        continue
    
    # í†µê³„ ê³„ì‚°
    if results:
        pck_01_scores = [r["pck_0.1"] for r in results]
        pck_02_scores = [r["pck_0.2"] for r in results]
        pckh_05_scores = [r["pckh_0.5"] for r in results]
        
        statistics = {
            "mean_pck_0.1": round(float(np.mean(pck_01_scores)), 4),
            "mean_pck_0.2": round(float(np.mean(pck_02_scores)), 4),
            "mean_pckh_0.5": round(float(np.mean(pckh_05_scores)), 4),
            "std_pck_0.1": round(float(np.std(pck_01_scores)), 4),
            "std_pck_0.2": round(float(np.std(pck_02_scores)), 4),
            "std_pckh_0.5": round(float(np.std(pckh_05_scores)), 4),
            "total_images": len(results),
        }
    else:
        statistics = {
            "mean_pck_0.1": None,
            "mean_pck_0.2": None,
            "mean_pckh_0.5": None,
            "std_pck_0.1": None,
            "std_pck_0.2": None,
            "std_pckh_0.5": None,
            "total_images": 0,
        }
    
    # ê²°ê³¼ ì €ì¥
    output_data = {
        "model": model_name,
        "prompt_version": prompt_version,
        "statistics": statistics,
        "results": results,
        "timestamp": datetime.now().isoformat()
    }
    
    output_file = output_dir / model_name / f"{prompt_version}_pck_results.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
    
    if statistics["total_images"] > 0:
        print(f"\nğŸ“Š í†µê³„:")
        print(f"  í‰ê·  PCK@0.1: {statistics['mean_pck_0.1']:.4f}")
        print(f"  í‰ê·  PCK@0.2: {statistics['mean_pck_0.2']:.4f}")
        print(f"  í‰ê·  PCKh@0.5: {statistics['mean_pckh_0.5']:.4f}")
        print(f"  ì´ ì´ë¯¸ì§€ ìˆ˜: {statistics['total_images']}")
    
    print(f"\n{'='*60}")
    print("í‰ê°€ ì™„ë£Œ")
    print(f"{'='*60}\n")
    
    return output_data


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="extracted_keypointsì˜ originalê³¼ ìƒì„± ëª¨ë¸ ê°„ PCK/PCKh í‰ê°€",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # nano_banana ëª¨ë¸ì˜ short í”„ë¡¬í”„íŠ¸ í‰ê°€
  python metrics/pck/evaluate_extracted_keypoints.py --model nano_banana --prompt short
  
  # ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ ë²„ì „ í‰ê°€
  python metrics/pck/evaluate_extracted_keypoints.py --model nano_banana --prompt short medium long
        """
    )
    
    parser.add_argument(
        "--model",
        type=str,
        required=True,
        help="ëª¨ë¸ ì´ë¦„ (ì˜ˆ: nano_banana)"
    )
    
    parser.add_argument(
        "--prompt",
        nargs="+",
        default=["short", "medium", "long"],
        help="í”„ë¡¬í”„íŠ¸ ë²„ì „ (ê¸°ë³¸ê°’: short medium long)"
    )
    
    parser.add_argument(
        "--extracted_keypoints_dir",
        type=str,
        default="extracted_keypoints",
        help="extracted_keypoints ê¸°ë³¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: extracted_keypoints)"
    )
    
    parser.add_argument(
        "--output_dir",
        type=str,
        default="evaluations/pck",
        help="ê²°ê³¼ ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: evaluations/pck)"
    )
    
    args = parser.parse_args()
    
    # í‰ê°€ ì‹¤í–‰
    for prompt_version in args.prompt:
        evaluate_extracted_keypoints(
            model_name=args.model,
            prompt_version=prompt_version,
            extracted_keypoints_base=Path(args.extracted_keypoints_dir),
            output_dir=Path(args.output_dir)
        )


if __name__ == "__main__":
    main()
