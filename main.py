"""
í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìë™í™” ìŠ¤í¬ë¦½íŠ¸

3ê°œ ëª¨ë¸ Ã— 3ê°œ í”„ë¡¬í”„íŠ¸ ë²„ì „ = 9ê°œ ì¡°í•©ì— ëŒ€í•´
ê° ì´ë¯¸ì§€ íƒ€ì…(full, half, selfie)ë³„ë¡œ í‚¤í¬ì¸íŠ¸ë¥¼ ì ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import json
import argparse
from pathlib import Path

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ê²½ê³ ë§Œ ì¶œë ¥
    pass

from models import NanoBanana, StableDiffusion, QwenControlnet
from utils import (
    load_image,
    get_image_files,
    get_keypoint_path,
    create_output_path
)
from metrics.timer import elapse_time

# ëª¨ë¸ ë° í”„ë¡¬í”„íŠ¸ ì„¤ì •
MODELS = {
    "nano_banana": NanoBanana,
    "stable_diffusion": StableDiffusion,
    "qwen_controlnet": QwenControlnet
}

PROMPT_VERSIONS = ["short", "medium", "long"]
IMAGE_TYPES = ["full", "half", "selfie"]
KP_NUMS = [1, 2, 3]


def get_prompt_path(model_name, prompt_version):
    """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return Path(f"prompts/{model_name}/{prompt_version}.txt")


def process_single_case(model_name, prompt_version, image_type, bg_type, image_path, kp_num):
    """
    ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        model_name: ëª¨ë¸ ì´ë¦„
        prompt_version: í”„ë¡¬í”„íŠ¸ ë²„ì „ ('short', 'medium', 'long')
        image_type: ì´ë¯¸ì§€ íƒ€ì… ('full', 'half', 'selfie')
        bg_type: ë°°ê²½ íƒ€ì… ('bg', 'no_bg', None)
        image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
        kp_num: í‚¤í¬ì¸íŠ¸ ë²ˆí˜¸ (1, 2, 3)
    
    Returns:
        ìƒì„±ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    try:
        # ëª¨ë¸ ì´ˆê¸°í™”
        prompt_path = get_prompt_path(model_name, prompt_version)
        if not prompt_path.exists():
            print(f"âš ï¸  í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {prompt_path}")
            return None
        
        model_class = MODELS[model_name]
        model = model_class(str(prompt_path))
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        input_image = load_image(image_path)
        
        # í‚¤í¬ì¸íŠ¸ ë¡œë“œ (selfieëŠ” half í‚¤í¬ì¸íŠ¸ ì‚¬ìš©)
        kp_type = "half" if image_type == "selfie" else image_type
        kp_path = get_keypoint_path(kp_type, kp_num)
        if not kp_path.exists():
            print(f"âš ï¸  í‚¤í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {kp_path}")
            return None
        
        pose_image = load_image(kp_path)
        
        # ì¶œë ¥ ê²½ë¡œ ìƒì„±
        image_name = image_path.stem  # í™•ì¥ì ì œì™¸í•œ íŒŒì¼ëª…
        output_path = create_output_path(
            model_name, prompt_version, image_type, bg_type, image_name, kp_num
        )
        
        # ì´ë¯¸ì§€ ìƒì„±
        result = model.generate(input_image, pose_image, output_path)
        
        # ê²°ê³¼ê°€ dictì¸ ê²½ìš° (ì‹œê°„/í† í° ì •ë³´ í¬í•¨)ì™€ strì¸ ê²½ìš° (ê¸°ì¡´ í˜•ì‹) ëª¨ë‘ ì²˜ë¦¬
        if isinstance(result, dict):
            return result
        else:
            # ê¸°ì¡´ í˜•ì‹ (ë¬¸ìì—´ë§Œ ë°˜í™˜) - í˜¸í™˜ì„±ì„ ìœ„í•´ dictë¡œ ë³€í™˜
            return {
                "saved_path": result,
                "generation_time": 0,
                "total_tokens": 0,
                "input_tokens": 0,
                "output_tokens": 0
            }
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {model_name}/{prompt_version}/{image_type}/{bg_type}/{image_path.name}_kp_{kp_num}")
        print(f"   ì˜¤ë¥˜ ë‚´ìš©: {str(e)}")
        return None


def save_token_time_json(model_name, prompt_version, results_dict):
    """
    ì‹œê°„ê³¼ í† í° ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        model_name: ëª¨ë¸ ì´ë¦„
        prompt_version: í”„ë¡¬í”„íŠ¸ ë²„ì „
        results_dict: {íŒŒì¼ê²½ë¡œ: {generation_time, total_tokens, input_tokens, output_tokens}} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    output_dir = Path(f"results/{model_name}/{prompt_version}")
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / "token_time_result.json"
    
    # ì†Œìˆ˜ì  1ìë¦¬ë¡œ ë³€í™˜
    formatted_results = {}
    for file_path, info in results_dict.items():
        formatted_results[file_path] = {
            "generation_time": round(info["generation_time"], 1),
            "total_tokens": info["total_tokens"],
            "input_tokens": info["input_tokens"],
            "output_tokens": info["output_tokens"]
        }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(formatted_results, f, indent=2, ensure_ascii=False)
    
    print(f"   ğŸ’¾ í† í°/ì‹œê°„ ì •ë³´ ì €ì¥: {output_file}")


def run_all_tests(model_names=None, prompt_versions=None, limit_images=None):
    """
    í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Args:
        model_names: ì‹¤í–‰í•  ëª¨ë¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ëª¨ë¸)
        prompt_versions: ì‹¤í–‰í•  í”„ë¡¬í”„íŠ¸ ë²„ì „ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ë²„ì „)
        limit_images: í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ìˆ˜ ì œí•œ (Noneì´ë©´ ëª¨ë“  ì´ë¯¸ì§€)
    """
    
    # ê¸°ë³¸ê°’ ì„¤ì •
    if model_names is None:
        model_names = list(MODELS.keys())
    if prompt_versions is None:
        prompt_versions = PROMPT_VERSIONS
    
    # ìœ íš¨ì„± ê²€ì‚¬
    for model_name in model_names:
        if model_name not in MODELS:
            raise ValueError(f"ì˜ëª»ëœ ëª¨ë¸ ì´ë¦„: {model_name}. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(MODELS.keys())}")
    
    for prompt_version in prompt_versions:
        if prompt_version not in PROMPT_VERSIONS:
            raise ValueError(f"ì˜ëª»ëœ í”„ë¡¬í”„íŠ¸ ë²„ì „: {prompt_version}. ì‚¬ìš© ê°€ëŠ¥í•œ ë²„ì „: {PROMPT_VERSIONS}")
    
    total_cases = 0
    successful_cases = 0
    failed_cases = 0
    
    # ê° ëª¨ë¸ë³„ë¡œ ì²˜ë¦¬
    for model_name in model_names:
        print(f"\n{'='*60}")
        print(f"ëª¨ë¸: {model_name}")
        print(f"{'='*60}")
        
        # ê° í”„ë¡¬í”„íŠ¸ ë²„ì „ë³„ë¡œ ì²˜ë¦¬
        for prompt_version in prompt_versions:
            print(f"\n  í”„ë¡¬í”„íŠ¸ ë²„ì „: {prompt_version}")
            
            # í† í°/ì‹œê°„ ì •ë³´ ìˆ˜ì§‘ìš© ë”•ì…”ë„ˆë¦¬
            token_time_results = {}
            
            # ê° ëª¨ë¸/í”„ë¡¬í”„íŠ¸ ì¡°í•©ë³„ë¡œ ì‹œê°„ ì¸¡ì •
            with elapse_time():
                image_count = 0  # ì´ë¯¸ì§€ ì¹´ìš´í„° (limit_images ì œí•œìš©)
                
                # ê° ì´ë¯¸ì§€ íƒ€ì…ë³„ë¡œ ì²˜ë¦¬
                for image_type in IMAGE_TYPES:
                    if limit_images and image_count >= limit_images:
                        print(f"    âš ï¸  ì´ë¯¸ì§€ ì œí•œ ë„ë‹¬ ({limit_images}ê°œ), ì¤‘ë‹¨")
                        break
                    
                    print(f"    ì´ë¯¸ì§€ íƒ€ì…: {image_type}")
                    
                    # ì´ë¯¸ì§€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
                    if image_type == "selfie":
                        # selfieëŠ” bg_type êµ¬ë¶„ ì—†ìŒ
                        image_files = get_image_files(image_type)
                        bg_type = None
                        
                        # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì²˜ë¦¬
                        for image_path in image_files:
                            if limit_images and image_count >= limit_images:
                                break
                            
                            # ê° í‚¤í¬ì¸íŠ¸ì— ëŒ€í•´ ì²˜ë¦¬
                            for kp_num in KP_NUMS:
                                if limit_images and image_count >= limit_images:
                                    break
                                
                                total_cases += 1
                                image_count += 1
                                
                                case_info = (
                                    f"{model_name}/{prompt_version}/{image_type}/"
                                    f"none/{image_path.name}_kp_{kp_num}"
                                )
                                
                                result = process_single_case(
                                    model_name, prompt_version, image_type, 
                                    bg_type, image_path, kp_num
                                )
                                
                                if result and isinstance(result, dict) and result.get("saved_path"):
                                    successful_cases += 1
                                    print(f"      âœ“ {case_info}")
                                    
                                    # í† í°/ì‹œê°„ ì •ë³´ ì €ì¥
                                    file_path = result["saved_path"]
                                    token_time_results[file_path] = {
                                        "generation_time": result.get("generation_time", 0),
                                        "total_tokens": result.get("total_tokens", 0),
                                        "input_tokens": result.get("input_tokens", 0),
                                        "output_tokens": result.get("output_tokens", 0)
                                    }
                                else:
                                    failed_cases += 1
                                    print(f"      âœ— {case_info}")
                    else:
                        # full, halfëŠ” bg/no_bg êµ¬ë¶„
                        for bg_type in ["bg", "no_bg"]:
                            if limit_images and image_count >= limit_images:
                                break
                            
                            image_files = get_image_files(image_type, bg_type)
                            
                            # ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ì²˜ë¦¬
                            for image_path in image_files:
                                if limit_images and image_count >= limit_images:
                                    break
                                
                                # ê° í‚¤í¬ì¸íŠ¸ì— ëŒ€í•´ ì²˜ë¦¬
                                for kp_num in KP_NUMS:
                                    if limit_images and image_count >= limit_images:
                                        break
                                    
                                    total_cases += 1
                                    image_count += 1
                                    
                                    case_info = (
                                        f"{model_name}/{prompt_version}/{image_type}/"
                                        f"{bg_type}/{image_path.name}_kp_{kp_num}"
                                    )
                                    
                                    result = process_single_case(
                                        model_name, prompt_version, image_type, 
                                        bg_type, image_path, kp_num
                                    )
                                    
                                    if result and isinstance(result, dict) and result.get("saved_path"):
                                        successful_cases += 1
                                        print(f"      âœ“ {case_info}")
                                        
                                        # í† í°/ì‹œê°„ ì •ë³´ ì €ì¥
                                        file_path = result["saved_path"]
                                        token_time_results[file_path] = {
                                            "generation_time": result.get("generation_time", 0),
                                            "total_tokens": result.get("total_tokens", 0),
                                            "input_tokens": result.get("input_tokens", 0),
                                            "output_tokens": result.get("output_tokens", 0)
                                        }
                                    else:
                                        failed_cases += 1
                                        print(f"      âœ— {case_info}")
            
            # í† í°/ì‹œê°„ ì •ë³´ JSON ì €ì¥
            if token_time_results:
                save_token_time_json(model_name, prompt_version, token_time_results)
                    
    # ìµœì¢… í†µê³„ ì¶œë ¥
    print(f"\n{'='*60}")
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print(f"{'='*60}")
    print(f"ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {total_cases}")
    print(f"ì„±ê³µ: {successful_cases}")
    print(f"ì‹¤íŒ¨: {failed_cases}")
    print(f"ì„±ê³µë¥ : {successful_cases/total_cases*100:.2f}%" if total_cases > 0 else "N/A")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìë™í™” ìŠ¤í¬ë¦½íŠ¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # nano_banana ëª¨ë¸ì˜ short í”„ë¡¬í”„íŠ¸ë§Œ ì‹¤í–‰
  python main.py --model nano_banana --prompt short
  
  # ì—¬ëŸ¬ ëª¨ë¸ê³¼ í”„ë¡¬í”„íŠ¸ ì¡°í•© ì‹¤í–‰
  python main.py --model nano_banana stable_diffusion --prompt short medium
  
  # ëª¨ë“  ëª¨ë¸ê³¼ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ (ì¸ì ì—†ì´)
  python main.py
        """
    )
    
    parser.add_argument(
        "--model",
        nargs="+",
        choices=list(MODELS.keys()),
        default=None,
        help=f"ì‹¤í–‰í•  ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: ëª¨ë“  ëª¨ë¸). ì„ íƒ ê°€ëŠ¥: {', '.join(MODELS.keys())}"
    )
    
    parser.add_argument(
        "--prompt",
        nargs="+",
        choices=PROMPT_VERSIONS,
        default=None,
        help=f"ì‹¤í–‰í•  í”„ë¡¬í”„íŠ¸ ë²„ì „ (ê¸°ë³¸ê°’: ëª¨ë“  ë²„ì „). ì„ íƒ ê°€ëŠ¥: {', '.join(PROMPT_VERSIONS)}"
    )
    
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ìˆ˜ë¥¼ ì œí•œí•©ë‹ˆë‹¤ (ì˜ˆ: 3)."
    )
    
    args = parser.parse_args()
    
    # results ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs("results", exist_ok=True)
    
    # ì‹¤í–‰ ì •ë³´ ì¶œë ¥
    model_names = args.model if args.model else list(MODELS.keys())
    prompt_versions = args.prompt if args.prompt else PROMPT_VERSIONS
    
    print("í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìë™í™” ì‹œì‘")
    print(f"ëª¨ë¸: {', '.join(model_names)}")
    print(f"í”„ë¡¬í”„íŠ¸ ë²„ì „: {', '.join(prompt_versions)}")
    print(f"ì´ë¯¸ì§€ íƒ€ì…: {len(IMAGE_TYPES)}ê°œ ({', '.join(IMAGE_TYPES)})")
    print(f"í‚¤í¬ì¸íŠ¸ ë²„ì „: {len(KP_NUMS)}ê°œ")
    if args.limit:
        print(f"âš ï¸  ì´ë¯¸ì§€ ì œí•œ: {args.limit}ê°œë§Œ í…ŒìŠ¤íŠ¸")
    print()
    
    # elapse_timeìœ¼ë¡œ ì „ì²´ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
    with elapse_time():
        run_all_tests(
            model_names=model_names, 
            prompt_versions=prompt_versions,
            limit_images=args.limit
        )


if __name__ == "__main__":
    main()
